{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2db70c22-6f2a-4409-80eb-bd90e6a0351c",
   "metadata": {},
   "source": [
    "## Conv Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2860445b-0f9b-4f78-8e3d-a3d9c3cbba6c",
   "metadata": {},
   "source": [
    "### Shapes of Conv Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02eddcda-9819-40f6-bce0-d027491ced3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28, 5)\n",
      "(3, 3, 5, 10)\n",
      "(10,)\n",
      "(32, 26, 26, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "N, n_H, n_W, n_C = 32, 28, 28, 5\n",
    "n_filter = 10\n",
    "k_size = 3\n",
    "\n",
    "images = tf.random.uniform(minval=0, maxval=1, shape = ((N, n_H, n_W, n_C)))\n",
    "\n",
    "print(images.shape)\n",
    "\n",
    "conv = Conv2D(filters=n_filter, kernel_size=k_size)\n",
    "\n",
    "y = conv(images)\n",
    "W, B = conv.get_weights()\n",
    "\n",
    "print(W.shape)\n",
    "print(B.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae537621-d1b3-47b7-8870-c8aab5c23ce5",
   "metadata": {},
   "source": [
    "### Correlation Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c79eb1b-2552-4afc-99b0-1ee91177630d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5, 5, 1)\n",
      "(3, 3, 1, 1)\n",
      "(1,)\n",
      "(1, 3, 3, 1)\n",
      "Y(tensorflow) : \n",
      " [[-0.40100697  0.08786326 -0.39688262]\n",
      " [-0.14414974  0.05167706 -0.51198244]\n",
      " [-0.28092736 -0.36168802 -0.31240967]]\n",
      "Y(manual) : \n",
      " [[-0.40100694  0.08786324 -0.39688259]\n",
      " [-0.14414972  0.05167701 -0.51198244]\n",
      " [-0.2809273  -0.36168799 -0.31240964]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "N, n_H, n_W, n_C = 1, 5, 5, 1\n",
    "n_filter = 1\n",
    "k_size = 3\n",
    "\n",
    "images = tf.random.uniform(minval=0, maxval=1, shape = ((N, n_H, n_W, n_C)))\n",
    "\n",
    "print(images.shape)\n",
    "\n",
    "conv = Conv2D(filters=n_filter, kernel_size=k_size)\n",
    "\n",
    "y = conv(images)\n",
    "W, B = conv.get_weights()\n",
    "\n",
    "print(W.shape)\n",
    "print(B.shape)\n",
    "print(y.shape)\n",
    "print(\"Y(tensorflow) : \\n\", y.numpy().squeeze())\n",
    "\n",
    "images = images.numpy().squeeze()\n",
    "W = W.squeeze()\n",
    "\n",
    "y_man = np.zeros(shape=(n_H - k_size + 1, n_W - k_size + 1))\n",
    "for i in range(n_H - k_size + 1):\n",
    "    for j in range(n_W - k_size + 1):\n",
    "        window = images[i : i+k_size, j : j+k_size]\n",
    "        y_man[i, j] = np.sum(window*W) + B\n",
    "print('Y(manual) : \\n', y_man)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b85fd6-1141-4fc9-afca-364ed99fb2b8",
   "metadata": {},
   "source": [
    "### Correlation with n-channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d99452b5-a2fe-4d41-95fe-e669ede84e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y(tensorflow) : \n",
      " [[-1.0690262  -0.78065115  0.11340525]\n",
      " [-0.194404   -0.28601158 -0.28410292]\n",
      " [-0.53984445  0.10284387 -0.74632025]]\n",
      "Y(manual) : \n",
      " [[-1.06902623 -0.78065121  0.11340525]\n",
      " [-0.19440407 -0.28601155 -0.28410298]\n",
      " [-0.53984445  0.10284397 -0.74632031]]\n"
     ]
    }
   ],
   "source": [
    "# 3 channel\n",
    "N, n_H, n_W, n_C = 1, 5, 5, 3\n",
    "n_filter = 1\n",
    "k_size = 3\n",
    "\n",
    "images = tf.random.uniform(minval=0, maxval=1, shape = ((N, n_H, n_W, n_C)))\n",
    "\n",
    "# print(images.shape)\n",
    "\n",
    "conv = Conv2D(filters=n_filter, kernel_size=k_size)\n",
    "\n",
    "y = conv(images)\n",
    "W, B = conv.get_weights()\n",
    "\n",
    "print(\"Y(tensorflow) : \\n\", y.numpy().squeeze())\n",
    "\n",
    "images = images.numpy().squeeze()\n",
    "W = W.squeeze()\n",
    "\n",
    "y_man = np.zeros(shape=(n_H - k_size + 1, n_W - k_size + 1))\n",
    "for i in range(n_H - k_size + 1):\n",
    "    for j in range(n_W - k_size + 1):\n",
    "        window = images[i : i+k_size, j : j+k_size, :]\n",
    "        y_man[i, j] = np.sum(window*W) + B\n",
    "print('Y(manual) : \\n', y_man)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7402a0-9a1a-482c-9171-3a77d4f3725c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c362316-8ce1-403b-8ff1-6d6dacd6fe0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcbc6f9-7110-4f08-aec5-c05fb3bace9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aea6d8d-1682-46ad-8666-980eb1da69fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245baf50-746d-4b9c-9df5-e8bacb888cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b1ee0e-6e54-421d-85dc-19fe2179e504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
