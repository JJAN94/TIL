{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":357,"status":"ok","timestamp":1645184952023,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"},"user_tz":-540},"id":"9pbpr5QLYZHw"},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os"]},{"cell_type":"markdown","metadata":{"id":"IheHZO4FYZHz"},"source":["### Keras의 Pretrained 모델 로딩 및 모델 구조 확인. "]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4117,"status":"ok","timestamp":1645184956532,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"},"user_tz":-540},"id":"gUe009FKYZH1"},"outputs":[],"source":["#from tensorflow.keras.applications.vgg16 import VGG16\n","#from tensorflow.keras.applications.resnet50 import ResNet50\n","from tensorflow.keras.applications import VGG16, ResNet50, ResNet50V2, Xception"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5441,"status":"ok","timestamp":1645184961968,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"},"user_tz":-540},"id":"-8tIfZB6YZH1","outputId":"003bea34-a60f-459b-cca4-4baed6cd8638"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 25088)             0         \n","                                                                 \n"," fc1 (Dense)                 (None, 4096)              102764544 \n","                                                                 \n"," fc2 (Dense)                 (None, 4096)              16781312  \n","                                                                 \n"," predictions (Dense)         (None, 1000)              4097000   \n","                                                                 \n","=================================================================\n","Total params: 138,357,544\n","Trainable params: 138,357,544\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model = VGG16()\n","model.summary()"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":727,"status":"ok","timestamp":1645184962692,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"},"user_tz":-540},"id":"xbUC8v5NYZH2","outputId":"276c2f27-a25b-44e9-f9a1-467793e777fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_2 (InputLayer)        [(None, 32, 32, 3)]       0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n","                                                                 \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["model = VGG16(input_shape=(32, 32, 3), include_top=False, weights='imagenet')\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"MRYzQjXFYZH2"},"source":["### Keras의 Model 역시 Functional임. "]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1645184962693,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"},"user_tz":-540},"id":"y4Ffn5BXYZH3","outputId":"1a8ba84f-f785-4585-b18e-62d17a7d7fd4"},"outputs":[{"output_type":"stream","name":"stdout","text":["model: <keras.engine.functional.Functional object at 0x7f78c00c82d0>\n","model output: KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 512), dtype=tf.float32, name=None), name='block5_pool/MaxPool:0', description=\"created by layer 'block5_pool'\")\n"]}],"source":["print('model:', model)\n","print('model output:', model.output)"]},{"cell_type":"markdown","metadata":{"id":"1cJvFLltYZH4"},"source":["### Pretrained 모델을 기반으로 CIFAR 10 분류 모델 재 생성. "]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1645184962693,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"},"user_tz":-540},"id":"gSJOcRgCYZH4"},"outputs":[],"source":["IMAGE_SIZE = 32\n","BATCH_SIZE = 64"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":532,"status":"ok","timestamp":1645184963223,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"},"user_tz":-540},"id":"zDx34MrTYZH5","outputId":"9a28b397-6a5b-4462-eda7-3fb9875ae1e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 32, 32, 3)]       0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n","                                                                 \n"," global_average_pooling2d (G  (None, 512)              0         \n"," lobalAveragePooling2D)                                          \n","                                                                 \n"," fc1 (Dense)                 (None, 50)                25650     \n","                                                                 \n"," output (Dense)              (None, 10)                510       \n","                                                                 \n","=================================================================\n","Total params: 14,740,848\n","Trainable params: 14,740,848\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam , RMSprop \n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n","\n","# include_top=False로 기존 imagenet용 classifier 층들을 다 제거. weight는 전이학습을 위해 imagenet 학습된 weight를 초기 weight로 사용. \n","#input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n","#base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n","\n","base_model = VGG16(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), include_top=False, weights='imagenet')\n","bm_output = base_model.output\n","\n","# base model의 output을 입력으로 CIFAR10용 Classification layer를 재 구성. \n","x = GlobalAveragePooling2D()(bm_output)\n","# x = Dropout(rate=0.5)(x)\n","x = Dense(50, activation='relu', name='fc1')(x)\n","# x = Dropout(rate=0.2)(x)\n","output = Dense(10, activation='softmax', name='output')(x)\n","\n","#model = Model(inputs=input_tensor, outputs=output)\n","model = Model(inputs=base_model.input, outputs=output)\n","model.summary()"]},{"cell_type":"markdown","metadata":{"id":"t9_Mp6PKYZH5"},"source":["### 데이터 전처리 및 ImageDataGenerator로 Augmentation 설정하고 학습용, 검증용 Generator 생성"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1808,"status":"ok","timestamp":1645184965029,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"},"user_tz":-540},"id":"X6jB0HqAYZH6","outputId":"9c7bdca9-c543-48ce-f61b-f1c75abceb1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n","(42500, 32, 32, 3) (42500, 10) (7500, 32, 32, 3) (7500, 10) (10000, 32, 32, 3) (10000, 10)\n"]}],"source":["import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","\n","import random as python_random\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.datasets import cifar10\n","\n","# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음. \n","def set_random_seed(seed_value):\n","    np.random.seed(seed_value)\n","    python_random.seed(seed_value)\n","    tf.random.set_seed(seed_value)\n","\n","# 0 ~ 1사이값의 float32로 변경하는 함수\n","def get_preprocessed_data(images, labels, scaling=True):\n","    \n","    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n","    if scaling:\n","        images = np.array(images/255.0, dtype=np.float32)\n","    else:\n","        images = np.array(images, dtype=np.float32)\n","        \n","    labels = np.array(labels, dtype=np.float32)\n","    \n","    return images, labels\n","\n","# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \n","def get_preprocessed_ohe(images, labels):\n","    images, labels = get_preprocessed_data(images, labels, scaling=False)\n","    # OHE 적용 \n","    oh_labels = to_categorical(labels)\n","    return images, oh_labels\n","\n","# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \n","def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n","    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n","    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n","    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n","    \n","    # 학습 데이터를 검증 데이터 세트로 다시 분리\n","    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n","    \n","    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n","\n","\n","# random seed는 2021로 고정.\n","set_random_seed(2021)\n","# CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n","(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n","print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)\n","\n","(tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n","    get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n","\n","print(tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1645184965320,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"},"user_tz":-540},"id":"msqKuaocYZH6"},"outputs":[],"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","train_generator = ImageDataGenerator(\n","    # rotation_range=20,\n","    #zoom_range=(0.7, 0.9),\n","    horizontal_flip=True,\n","    #vertical_flip=True,\n","    rescale=1/255.0\n",")\n","valid_generator = ImageDataGenerator(rescale=1/255.0)\n","\n","flow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)\n","flow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)"]},{"cell_type":"markdown","metadata":{"id":"_LTN6b7jYZH7"},"source":["### Keras CNN 모델 생성 함수. "]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":274,"status":"ok","timestamp":1645184968471,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"},"user_tz":-540},"id":"W9rALbpPYZH7"},"outputs":[],"source":["IMAGE_SIZE = 32\n","BATCH_SIZE = 64"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1645184969885,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"},"user_tz":-540},"id":"0vmtvs7rYZH7"},"outputs":[],"source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam , RMSprop \n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n","\n","def create_model(verbose=False):\n","    \n","    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n","    base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n","    bm_output = base_model.output\n","\n","    x = GlobalAveragePooling2D()(bm_output)\n","    #x = Dropout(rate=0.5)(x)\n","    x = Dense(50, activation='relu', name='fc1')(x)\n","    #x = Dropout(rate=0.2)(x)\n","    output = Dense(10, activation='softmax', name='output')(x)\n","\n","    model = Model(inputs=input_tensor, outputs=output)\n","    if verbose:\n","        model.summary()\n","        \n","    return model"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":671,"status":"ok","timestamp":1645184972986,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"},"user_tz":-540},"id":"cu6EoVgMYZH8","outputId":"bd831b9e-028a-4af8-b800-a0b0a591dbe3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n","                                                                 \n"," global_average_pooling2d_1   (None, 512)              0         \n"," (GlobalAveragePooling2D)                                        \n","                                                                 \n"," fc1 (Dense)                 (None, 50)                25650     \n","                                                                 \n"," output (Dense)              (None, 10)                510       \n","                                                                 \n","=================================================================\n","Total params: 14,740,848\n","Trainable params: 14,740,848\n","Non-trainable params: 0\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]}],"source":["vgg_model = create_model(verbose=True)\n","vgg_model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n","rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n","# 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n","ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ywvBRMYLYZH8","executionInfo":{"status":"ok","timestamp":1645185681280,"user_tz":-540,"elapsed":705959,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"}},"outputId":"d95ee7df-641f-4408-c923-9d26dda10051"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","665/665 [==============================] - 36s 40ms/step - loss: 1.8412 - accuracy: 0.2686 - val_loss: 1.5237 - val_accuracy: 0.3703 - lr: 0.0010\n","Epoch 2/40\n","665/665 [==============================] - 26s 39ms/step - loss: 1.2850 - accuracy: 0.5108 - val_loss: 1.0539 - val_accuracy: 0.6300 - lr: 0.0010\n","Epoch 3/40\n","665/665 [==============================] - 26s 39ms/step - loss: 0.9920 - accuracy: 0.6546 - val_loss: 0.9192 - val_accuracy: 0.6892 - lr: 0.0010\n","Epoch 4/40\n","665/665 [==============================] - 26s 39ms/step - loss: 0.8136 - accuracy: 0.7245 - val_loss: 0.7061 - val_accuracy: 0.7648 - lr: 0.0010\n","Epoch 5/40\n","665/665 [==============================] - 26s 39ms/step - loss: 0.7119 - accuracy: 0.7632 - val_loss: 0.7250 - val_accuracy: 0.7636 - lr: 0.0010\n","Epoch 6/40\n","665/665 [==============================] - 26s 39ms/step - loss: 0.6359 - accuracy: 0.7891 - val_loss: 0.6463 - val_accuracy: 0.7881 - lr: 0.0010\n","Epoch 7/40\n","665/665 [==============================] - 26s 39ms/step - loss: 0.5771 - accuracy: 0.8100 - val_loss: 0.6276 - val_accuracy: 0.7960 - lr: 0.0010\n","Epoch 8/40\n","665/665 [==============================] - 26s 38ms/step - loss: 0.5188 - accuracy: 0.8277 - val_loss: 0.6329 - val_accuracy: 0.7992 - lr: 0.0010\n","Epoch 9/40\n","665/665 [==============================] - 26s 39ms/step - loss: 0.4859 - accuracy: 0.8418 - val_loss: 0.5999 - val_accuracy: 0.8181 - lr: 0.0010\n","Epoch 10/40\n","665/665 [==============================] - 26s 39ms/step - loss: 0.4497 - accuracy: 0.8525 - val_loss: 0.5645 - val_accuracy: 0.8220 - lr: 0.0010\n","Epoch 11/40\n","665/665 [==============================] - 26s 39ms/step - loss: 0.4186 - accuracy: 0.8648 - val_loss: 0.5812 - val_accuracy: 0.8229 - lr: 0.0010\n","Epoch 12/40\n","665/665 [==============================] - 26s 39ms/step - loss: 0.3820 - accuracy: 0.8759 - val_loss: 0.5864 - val_accuracy: 0.8208 - lr: 0.0010\n","Epoch 13/40\n","665/665 [==============================] - 26s 38ms/step - loss: 0.3724 - accuracy: 0.8808 - val_loss: 0.5992 - val_accuracy: 0.8223 - lr: 0.0010\n","Epoch 14/40\n","665/665 [==============================] - 26s 39ms/step - loss: 0.3427 - accuracy: 0.8886 - val_loss: 0.5643 - val_accuracy: 0.8279 - lr: 0.0010\n","Epoch 15/40\n","665/665 [==============================] - 26s 39ms/step - loss: 0.3269 - accuracy: 0.8948 - val_loss: 0.6136 - val_accuracy: 0.8145 - lr: 0.0010\n","Epoch 16/40\n","665/665 [==============================] - 26s 39ms/step - loss: 0.2979 - accuracy: 0.9036 - val_loss: 0.5941 - val_accuracy: 0.8331 - lr: 0.0010\n","Epoch 17/40\n","665/665 [==============================] - 26s 39ms/step - loss: 0.2967 - accuracy: 0.9054 - val_loss: 0.5363 - val_accuracy: 0.8445 - lr: 0.0010\n","Epoch 18/40\n","665/665 [==============================] - 26s 39ms/step - loss: 0.2778 - accuracy: 0.9114 - val_loss: 0.5628 - val_accuracy: 0.8384 - lr: 0.0010\n","Epoch 19/40\n","665/665 [==============================] - 27s 40ms/step - loss: 0.2617 - accuracy: 0.9178 - val_loss: 0.5908 - val_accuracy: 0.8321 - lr: 0.0010\n","Epoch 20/40\n","665/665 [==============================] - 26s 38ms/step - loss: 0.2518 - accuracy: 0.9210 - val_loss: 0.6354 - val_accuracy: 0.8260 - lr: 0.0010\n","Epoch 21/40\n","665/665 [==============================] - 26s 39ms/step - loss: 0.2451 - accuracy: 0.9219 - val_loss: 0.5527 - val_accuracy: 0.8367 - lr: 0.0010\n","Epoch 22/40\n","665/665 [==============================] - ETA: 0s - loss: 0.2300 - accuracy: 0.9275\n","Epoch 22: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","665/665 [==============================] - 26s 39ms/step - loss: 0.2300 - accuracy: 0.9275 - val_loss: 0.6265 - val_accuracy: 0.8320 - lr: 0.0010\n","Epoch 23/40\n","665/665 [==============================] - 26s 39ms/step - loss: 0.1189 - accuracy: 0.9632 - val_loss: 0.5949 - val_accuracy: 0.8589 - lr: 2.0000e-04\n","Epoch 24/40\n","665/665 [==============================] - 26s 39ms/step - loss: 0.0775 - accuracy: 0.9776 - val_loss: 0.6068 - val_accuracy: 0.8623 - lr: 2.0000e-04\n","Epoch 25/40\n","665/665 [==============================] - 26s 39ms/step - loss: 0.0581 - accuracy: 0.9829 - val_loss: 0.6475 - val_accuracy: 0.8680 - lr: 2.0000e-04\n","Epoch 26/40\n","665/665 [==============================] - 26s 39ms/step - loss: 0.0453 - accuracy: 0.9875 - val_loss: 0.7041 - val_accuracy: 0.8620 - lr: 2.0000e-04\n","Epoch 27/40\n","665/665 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.9896\n","Epoch 27: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n","665/665 [==============================] - 26s 38ms/step - loss: 0.0403 - accuracy: 0.9896 - val_loss: 0.7234 - val_accuracy: 0.8629 - lr: 2.0000e-04\n","Epoch 27: early stopping\n"]}],"source":["# steps 횟수를 구하기 위해 학습 데이터의 건수와 검증 데이터의 건수를 구함. steps = ceil(학습 데이터 건수/BATCH_SIZE)\n","tr_data_len = tr_images.shape[0]\n","val_data_len = val_images.shape[0]\n","history = vgg_model.fit(flow_tr_gen, epochs=40, \n","                    steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)), \n","                    validation_data=flow_val_gen, validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n","                    callbacks=[rlr_cb, ely_cb])"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QRGpaZAQYZH8","executionInfo":{"status":"ok","timestamp":1645185683705,"user_tz":-540,"elapsed":2440,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"}},"outputId":"31905304-1b08-4db4-c172-6ed72ff78354"},"outputs":[{"output_type":"stream","name":"stdout","text":["157/157 [==============================] - 2s 14ms/step - loss: 0.8274 - accuracy: 0.8504\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.8273565173149109, 0.8503999710083008]"]},"metadata":{},"execution_count":14}],"source":["test_generator = ImageDataGenerator(rescale=1/255.0)\n","flow_test_gen = test_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n","vgg_model.evaluate(flow_test_gen)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"sSMKpTUqYZH8","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1645185684277,"user_tz":-540,"elapsed":575,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"}},"outputId":"e49b90a1-c2ab-463a-b7f1-4b35a6ad8ded"},"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","def show_history(history):\n","    plt.figure(figsize=(8, 4))\n","    plt.yticks(np.arange(0, 1, 0.05))\n","    plt.xticks(np.arange(0, 30, 2))\n","    plt.plot(history.history['accuracy'], label='train')\n","    plt.plot(history.history['val_accuracy'], label='valid')\n","    plt.legend()\n","    \n","show_history(history)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"LXNGCSG0YZH9","executionInfo":{"status":"ok","timestamp":1645184893229,"user_tz":-540,"elapsed":5,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"}}},"outputs":[],"source":[""]},{"cell_type":"markdown","metadata":{"id":"mhAlkyRnYZH9"},"source":["### 지금까지의 로직들을 함수화 "]},{"cell_type":"code","execution_count":1,"metadata":{"id":"nwQZyHUYYZH9","executionInfo":{"status":"ok","timestamp":1645185755698,"user_tz":-540,"elapsed":5069,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"}}},"outputs":[],"source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Input, Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D\n","from tensorflow.keras.optimizers import Adam , RMSprop \n","from tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","import cv2\n","\n","import random as python_random\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.datasets import cifar10\n","\n","from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras.applications import ResNet50V2\n","from tensorflow.keras.applications import Xception\n","\n","# seed 를 설정해서 학습시마다 동일한 결과 유도. 불행히도 의도한 대로 동작하지 않음. \n","def set_random_seed(seed_value):\n","    np.random.seed(seed_value)\n","    python_random.seed(seed_value)\n","    tf.random.set_seed(seed_value)\n","\n","# 0 ~ 1사이값의 float32로 변경하는 함수\n","def get_preprocessed_data(images, labels, scaling=True):\n","    \n","    # 학습과 테스트 이미지 array를 0~1 사이값으로 scale 및 float32 형 변형. \n","    if scaling:\n","        images = np.array(images/255.0, dtype=np.float32)\n","    else:\n","        images = np.array(images, dtype=np.float32)\n","        \n","    labels = np.array(labels, dtype=np.float32)\n","    \n","    return images, labels\n","\n","# 0 ~ 1사이값 float32로 변경하는 함수 호출 한 뒤 OHE 적용 \n","def get_preprocessed_ohe(images, labels):\n","    images, labels = get_preprocessed_data(images, labels, scaling=False)\n","    # OHE 적용 \n","    oh_labels = to_categorical(labels)\n","    return images, oh_labels\n","\n","# 학습/검증/테스트 데이터 세트에 전처리 및 OHE 적용한 뒤 반환 \n","def get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021):\n","    # 학습 및 테스트 데이터 세트를  0 ~ 1사이값 float32로 변경 및 OHE 적용. \n","    train_images, train_oh_labels = get_preprocessed_ohe(train_images, train_labels)\n","    test_images, test_oh_labels = get_preprocessed_ohe(test_images, test_labels)\n","    \n","    # 학습 데이터를 검증 데이터 세트로 다시 분리\n","    tr_images, val_images, tr_oh_labels, val_oh_labels = train_test_split(train_images, train_oh_labels, test_size=valid_size, random_state=random_state)\n","    \n","    return (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels ) \n","\n","# 입력 image의 크기를 resize 값 만큼 증가. CIFAR10의 이미지가 32x32로 작아서 마지막 feature map의 크기가 1로 되어 모델 성능이 좋지 않음. \n","# 마지막 feature map의 크기를 2로 만들기 위해 resize를 64로 하여 입력 이미지 크기를 변경. 단 메모리를 크게 소비하므로 64이상은 kernel이 다운됨. \n","def get_resized_images(images, resize=64):\n","    image_cnt = images.shape[0]\n","    resized_images = np.zeros((images.shape[0], resize, resize, 3))\n","    for i in range(image_cnt):\n","        resized_image = cv2.resize(images[i], (resize, resize))\n","        resized_images[i] = resized_image\n","    \n","    return resized_images\n","\n","def create_model(model_name='vgg16', verbose=False):\n","    \n","    input_tensor = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n","    if model_name == 'vgg16':\n","        base_model = VGG16(input_tensor=input_tensor, include_top=False, weights='imagenet')\n","    elif model_name == 'resnet50': # 케라스 ResNet50이 어떨땐 성능이 떨어져서 V2를 쓰자\n","        base_model = ResNet50V2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n","    elif model_name == 'xception':\n","        base_model = Xception(input_tensor=input_tensor, include_top=False, weights='imagenet')\n","    \n","    bm_output = base_model.output\n","\n","    x = GlobalAveragePooling2D()(bm_output)\n","    if model_name != 'vgg16':\n","        x = Dropout(rate=0.5)(x)\n","    x = Dense(50, activation='relu', name='fc1')(x)\n","    output = Dense(10, activation='softmax', name='output')(x)\n","\n","    model = Model(inputs=input_tensor, outputs=output)\n","    model.summary()\n","        \n","    return model"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"LLkstBjfYZH-","executionInfo":{"status":"ok","timestamp":1645185763165,"user_tz":-540,"elapsed":255,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"}}},"outputs":[],"source":["IMAGE_SIZE = 32\n","BATCH_SIZE = 64\n","\n","def do_cifar10_train_evaluation(image_size=IMAGE_SIZE, model_name='vgg16'):\n","    set_random_seed(2021)\n","    # CIFAR10 데이터 재 로딩 및 Scaling/OHE 전처리 적용하여 학습/검증/데이터 세트 생성. \n","    (train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n","    (tr_images, tr_oh_labels), (val_images, val_oh_labels), (test_images, test_oh_labels) = \\\n","        get_train_valid_test_set(train_images, train_labels, test_images, test_labels, valid_size=0.15, random_state=2021)\n","    print('데이터 세트 shape:', tr_images.shape, tr_oh_labels.shape, val_images.shape, val_oh_labels.shape, test_images.shape, test_oh_labels.shape)\n","    \n","    # 만약 image_size가 32보다 크면 이미지 크기 재조정. \n","    if image_size > 32:\n","        tr_images = get_resized_images(tr_images)\n","        val_images = get_resized_images(val_images)\n","        test_images = get_resized_images(test_images)\n","    \n","    # 학습/검증/테스트용 ImageDataGenerator와 flow로 pipeline 생성. \n","    train_generator = ImageDataGenerator(\n","        horizontal_flip=True,\n","        rescale=1/255.0\n","    )\n","    valid_generator = ImageDataGenerator(rescale=1/255.0)\n","    test_generator = ImageDataGenerator(rescale=1/255.0)\n","\n","    flow_tr_gen = train_generator.flow(tr_images, tr_oh_labels, batch_size=BATCH_SIZE, shuffle=True)\n","    flow_val_gen = valid_generator.flow(val_images, val_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n","    flow_test_gen = train_generator.flow(test_images, test_oh_labels, batch_size=BATCH_SIZE, shuffle=False)\n","    \n","    # model_name 에 따른 모델 생성하고 모델 학습 및 검증 수행. \n","    model = create_model(model_name=model_name, verbose=True)\n","    model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    # 5번 iteration내에 validation loss가 향상되지 않으면 learning rate을 기존 learning rate * 0.2로 줄임.  \n","    rlr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, mode='min', verbose=1)\n","    # 10번 iteration내에 validation loss가 향상되지 않으면 더 이상 학습하지 않고 종료\n","    ely_cb = EarlyStopping(monitor='val_loss', patience=10, mode='min', verbose=1)\n","    \n","    tr_data_len = tr_images.shape[0]\n","    val_data_len = val_images.shape[0]\n","    history = model.fit(flow_tr_gen, epochs=40, \n","                        steps_per_epoch=int(np.ceil(tr_data_len/BATCH_SIZE)), \n","                        validation_data=flow_val_gen, validation_steps=int(np.ceil(val_data_len/BATCH_SIZE)),\n","                        callbacks=[rlr_cb, ely_cb])\n","    # 테스트 데이터 세트로 모델 성능 검증 \n","    evaluation_result = model.evaluate(flow_test_gen)\n","    print('테스트 데이터 세트 evaluation 결과:', evaluation_result)\n","    return history, evaluation_result\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"PX0llVzGYZH_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645185766791,"user_tz":-540,"elapsed":251,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"}},"outputId":"caa8cdc7-6ce7-4a73-c6a8-4ddedfb5672c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["99"]},"metadata":{},"execution_count":3}],"source":["import gc\n","\n","gc.collect()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"CDgO4sB9YZH_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645187767581,"user_tz":-540,"elapsed":1998745,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"}},"outputId":"9f44b96a-816f-4db7-d289-b288c1e62b17"},"outputs":[{"output_type":"stream","name":"stdout","text":["데이터 세트 shape: (42500, 32, 32, 3) (42500, 10) (7500, 32, 32, 3) (7500, 10) (10000, 32, 32, 3) (10000, 10)\n","Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n","83689472/83683744 [==============================] - 1s 0us/step\n","83697664/83683744 [==============================] - 1s 0us/step\n","Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n","                                                                                                  \n"," block1_conv1 (Conv2D)          (None, 15, 15, 32)   864         ['input_1[0][0]']                \n","                                                                                                  \n"," block1_conv1_bn (BatchNormaliz  (None, 15, 15, 32)  128         ['block1_conv1[0][0]']           \n"," ation)                                                                                           \n","                                                                                                  \n"," block1_conv1_act (Activation)  (None, 15, 15, 32)   0           ['block1_conv1_bn[0][0]']        \n","                                                                                                  \n"," block1_conv2 (Conv2D)          (None, 13, 13, 64)   18432       ['block1_conv1_act[0][0]']       \n","                                                                                                  \n"," block1_conv2_bn (BatchNormaliz  (None, 13, 13, 64)  256         ['block1_conv2[0][0]']           \n"," ation)                                                                                           \n","                                                                                                  \n"," block1_conv2_act (Activation)  (None, 13, 13, 64)   0           ['block1_conv2_bn[0][0]']        \n","                                                                                                  \n"," block2_sepconv1 (SeparableConv  (None, 13, 13, 128)  8768       ['block1_conv2_act[0][0]']       \n"," 2D)                                                                                              \n","                                                                                                  \n"," block2_sepconv1_bn (BatchNorma  (None, 13, 13, 128)  512        ['block2_sepconv1[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," block2_sepconv2_act (Activatio  (None, 13, 13, 128)  0          ['block2_sepconv1_bn[0][0]']     \n"," n)                                                                                               \n","                                                                                                  \n"," block2_sepconv2 (SeparableConv  (None, 13, 13, 128)  17536      ['block2_sepconv2_act[0][0]']    \n"," 2D)                                                                                              \n","                                                                                                  \n"," block2_sepconv2_bn (BatchNorma  (None, 13, 13, 128)  512        ['block2_sepconv2[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," conv2d (Conv2D)                (None, 7, 7, 128)    8192        ['block1_conv2_act[0][0]']       \n","                                                                                                  \n"," block2_pool (MaxPooling2D)     (None, 7, 7, 128)    0           ['block2_sepconv2_bn[0][0]']     \n","                                                                                                  \n"," batch_normalization (BatchNorm  (None, 7, 7, 128)   512         ['conv2d[0][0]']                 \n"," alization)                                                                                       \n","                                                                                                  \n"," add (Add)                      (None, 7, 7, 128)    0           ['block2_pool[0][0]',            \n","                                                                  'batch_normalization[0][0]']    \n","                                                                                                  \n"," block3_sepconv1_act (Activatio  (None, 7, 7, 128)   0           ['add[0][0]']                    \n"," n)                                                                                               \n","                                                                                                  \n"," block3_sepconv1 (SeparableConv  (None, 7, 7, 256)   33920       ['block3_sepconv1_act[0][0]']    \n"," 2D)                                                                                              \n","                                                                                                  \n"," block3_sepconv1_bn (BatchNorma  (None, 7, 7, 256)   1024        ['block3_sepconv1[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," block3_sepconv2_act (Activatio  (None, 7, 7, 256)   0           ['block3_sepconv1_bn[0][0]']     \n"," n)                                                                                               \n","                                                                                                  \n"," block3_sepconv2 (SeparableConv  (None, 7, 7, 256)   67840       ['block3_sepconv2_act[0][0]']    \n"," 2D)                                                                                              \n","                                                                                                  \n"," block3_sepconv2_bn (BatchNorma  (None, 7, 7, 256)   1024        ['block3_sepconv2[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," conv2d_1 (Conv2D)              (None, 4, 4, 256)    32768       ['add[0][0]']                    \n","                                                                                                  \n"," block3_pool (MaxPooling2D)     (None, 4, 4, 256)    0           ['block3_sepconv2_bn[0][0]']     \n","                                                                                                  \n"," batch_normalization_1 (BatchNo  (None, 4, 4, 256)   1024        ['conv2d_1[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add_1 (Add)                    (None, 4, 4, 256)    0           ['block3_pool[0][0]',            \n","                                                                  'batch_normalization_1[0][0]']  \n","                                                                                                  \n"," block4_sepconv1_act (Activatio  (None, 4, 4, 256)   0           ['add_1[0][0]']                  \n"," n)                                                                                               \n","                                                                                                  \n"," block4_sepconv1 (SeparableConv  (None, 4, 4, 728)   188672      ['block4_sepconv1_act[0][0]']    \n"," 2D)                                                                                              \n","                                                                                                  \n"," block4_sepconv1_bn (BatchNorma  (None, 4, 4, 728)   2912        ['block4_sepconv1[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," block4_sepconv2_act (Activatio  (None, 4, 4, 728)   0           ['block4_sepconv1_bn[0][0]']     \n"," n)                                                                                               \n","                                                                                                  \n"," block4_sepconv2 (SeparableConv  (None, 4, 4, 728)   536536      ['block4_sepconv2_act[0][0]']    \n"," 2D)                                                                                              \n","                                                                                                  \n"," block4_sepconv2_bn (BatchNorma  (None, 4, 4, 728)   2912        ['block4_sepconv2[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," conv2d_2 (Conv2D)              (None, 2, 2, 728)    186368      ['add_1[0][0]']                  \n","                                                                                                  \n"," block4_pool (MaxPooling2D)     (None, 2, 2, 728)    0           ['block4_sepconv2_bn[0][0]']     \n","                                                                                                  \n"," batch_normalization_2 (BatchNo  (None, 2, 2, 728)   2912        ['conv2d_2[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add_2 (Add)                    (None, 2, 2, 728)    0           ['block4_pool[0][0]',            \n","                                                                  'batch_normalization_2[0][0]']  \n","                                                                                                  \n"," block5_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_2[0][0]']                  \n"," n)                                                                                               \n","                                                                                                  \n"," block5_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block5_sepconv1_act[0][0]']    \n"," 2D)                                                                                              \n","                                                                                                  \n"," block5_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block5_sepconv1[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," block5_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block5_sepconv1_bn[0][0]']     \n"," n)                                                                                               \n","                                                                                                  \n"," block5_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block5_sepconv2_act[0][0]']    \n"," 2D)                                                                                              \n","                                                                                                  \n"," block5_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block5_sepconv2[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," block5_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block5_sepconv2_bn[0][0]']     \n"," n)                                                                                               \n","                                                                                                  \n"," block5_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block5_sepconv3_act[0][0]']    \n"," 2D)                                                                                              \n","                                                                                                  \n"," block5_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block5_sepconv3[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," add_3 (Add)                    (None, 2, 2, 728)    0           ['block5_sepconv3_bn[0][0]',     \n","                                                                  'add_2[0][0]']                  \n","                                                                                                  \n"," block6_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_3[0][0]']                  \n"," n)                                                                                               \n","                                                                                                  \n"," block6_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block6_sepconv1_act[0][0]']    \n"," 2D)                                                                                              \n","                                                                                                  \n"," block6_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block6_sepconv1[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," block6_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block6_sepconv1_bn[0][0]']     \n"," n)                                                                                               \n","                                                                                                  \n"," block6_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block6_sepconv2_act[0][0]']    \n"," 2D)                                                                                              \n","                                                                                                  \n"," block6_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block6_sepconv2[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," block6_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block6_sepconv2_bn[0][0]']     \n"," n)                                                                                               \n","                                                                                                  \n"," block6_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block6_sepconv3_act[0][0]']    \n"," 2D)                                                                                              \n","                                                                                                  \n"," block6_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block6_sepconv3[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," add_4 (Add)                    (None, 2, 2, 728)    0           ['block6_sepconv3_bn[0][0]',     \n","                                                                  'add_3[0][0]']                  \n","                                                                                                  \n"," block7_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_4[0][0]']                  \n"," n)                                                                                               \n","                                                                                                  \n"," block7_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block7_sepconv1_act[0][0]']    \n"," 2D)                                                                                              \n","                                                                                                  \n"," block7_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block7_sepconv1[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," block7_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block7_sepconv1_bn[0][0]']     \n"," n)                                                                                               \n","                                                                                                  \n"," block7_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block7_sepconv2_act[0][0]']    \n"," 2D)                                                                                              \n","                                                                                                  \n"," block7_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block7_sepconv2[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," block7_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block7_sepconv2_bn[0][0]']     \n"," n)                                                                                               \n","                                                                                                  \n"," block7_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block7_sepconv3_act[0][0]']    \n"," 2D)                                                                                              \n","                                                                                                  \n"," block7_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block7_sepconv3[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," add_5 (Add)                    (None, 2, 2, 728)    0           ['block7_sepconv3_bn[0][0]',     \n","                                                                  'add_4[0][0]']                  \n","                                                                                                  \n"," block8_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_5[0][0]']                  \n"," n)                                                                                               \n","                                                                                                  \n"," block8_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block8_sepconv1_act[0][0]']    \n"," 2D)                                                                                              \n","                                                                                                  \n"," block8_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block8_sepconv1[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," block8_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block8_sepconv1_bn[0][0]']     \n"," n)                                                                                               \n","                                                                                                  \n"," block8_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block8_sepconv2_act[0][0]']    \n"," 2D)                                                                                              \n","                                                                                                  \n"," block8_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block8_sepconv2[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," block8_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block8_sepconv2_bn[0][0]']     \n"," n)                                                                                               \n","                                                                                                  \n"," block8_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block8_sepconv3_act[0][0]']    \n"," 2D)                                                                                              \n","                                                                                                  \n"," block8_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block8_sepconv3[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," add_6 (Add)                    (None, 2, 2, 728)    0           ['block8_sepconv3_bn[0][0]',     \n","                                                                  'add_5[0][0]']                  \n","                                                                                                  \n"," block9_sepconv1_act (Activatio  (None, 2, 2, 728)   0           ['add_6[0][0]']                  \n"," n)                                                                                               \n","                                                                                                  \n"," block9_sepconv1 (SeparableConv  (None, 2, 2, 728)   536536      ['block9_sepconv1_act[0][0]']    \n"," 2D)                                                                                              \n","                                                                                                  \n"," block9_sepconv1_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block9_sepconv1[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," block9_sepconv2_act (Activatio  (None, 2, 2, 728)   0           ['block9_sepconv1_bn[0][0]']     \n"," n)                                                                                               \n","                                                                                                  \n"," block9_sepconv2 (SeparableConv  (None, 2, 2, 728)   536536      ['block9_sepconv2_act[0][0]']    \n"," 2D)                                                                                              \n","                                                                                                  \n"," block9_sepconv2_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block9_sepconv2[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," block9_sepconv3_act (Activatio  (None, 2, 2, 728)   0           ['block9_sepconv2_bn[0][0]']     \n"," n)                                                                                               \n","                                                                                                  \n"," block9_sepconv3 (SeparableConv  (None, 2, 2, 728)   536536      ['block9_sepconv3_act[0][0]']    \n"," 2D)                                                                                              \n","                                                                                                  \n"," block9_sepconv3_bn (BatchNorma  (None, 2, 2, 728)   2912        ['block9_sepconv3[0][0]']        \n"," lization)                                                                                        \n","                                                                                                  \n"," add_7 (Add)                    (None, 2, 2, 728)    0           ['block9_sepconv3_bn[0][0]',     \n","                                                                  'add_6[0][0]']                  \n","                                                                                                  \n"," block10_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_7[0][0]']                  \n"," on)                                                                                              \n","                                                                                                  \n"," block10_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block10_sepconv1_act[0][0]']   \n"," v2D)                                                                                             \n","                                                                                                  \n"," block10_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block10_sepconv1[0][0]']       \n"," alization)                                                                                       \n","                                                                                                  \n"," block10_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block10_sepconv1_bn[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," block10_sepconv2 (SeparableCon  (None, 2, 2, 728)   536536      ['block10_sepconv2_act[0][0]']   \n"," v2D)                                                                                             \n","                                                                                                  \n"," block10_sepconv2_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block10_sepconv2[0][0]']       \n"," alization)                                                                                       \n","                                                                                                  \n"," block10_sepconv3_act (Activati  (None, 2, 2, 728)   0           ['block10_sepconv2_bn[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," block10_sepconv3 (SeparableCon  (None, 2, 2, 728)   536536      ['block10_sepconv3_act[0][0]']   \n"," v2D)                                                                                             \n","                                                                                                  \n"," block10_sepconv3_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block10_sepconv3[0][0]']       \n"," alization)                                                                                       \n","                                                                                                  \n"," add_8 (Add)                    (None, 2, 2, 728)    0           ['block10_sepconv3_bn[0][0]',    \n","                                                                  'add_7[0][0]']                  \n","                                                                                                  \n"," block11_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_8[0][0]']                  \n"," on)                                                                                              \n","                                                                                                  \n"," block11_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block11_sepconv1_act[0][0]']   \n"," v2D)                                                                                             \n","                                                                                                  \n"," block11_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block11_sepconv1[0][0]']       \n"," alization)                                                                                       \n","                                                                                                  \n"," block11_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block11_sepconv1_bn[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," block11_sepconv2 (SeparableCon  (None, 2, 2, 728)   536536      ['block11_sepconv2_act[0][0]']   \n"," v2D)                                                                                             \n","                                                                                                  \n"," block11_sepconv2_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block11_sepconv2[0][0]']       \n"," alization)                                                                                       \n","                                                                                                  \n"," block11_sepconv3_act (Activati  (None, 2, 2, 728)   0           ['block11_sepconv2_bn[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," block11_sepconv3 (SeparableCon  (None, 2, 2, 728)   536536      ['block11_sepconv3_act[0][0]']   \n"," v2D)                                                                                             \n","                                                                                                  \n"," block11_sepconv3_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block11_sepconv3[0][0]']       \n"," alization)                                                                                       \n","                                                                                                  \n"," add_9 (Add)                    (None, 2, 2, 728)    0           ['block11_sepconv3_bn[0][0]',    \n","                                                                  'add_8[0][0]']                  \n","                                                                                                  \n"," block12_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_9[0][0]']                  \n"," on)                                                                                              \n","                                                                                                  \n"," block12_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block12_sepconv1_act[0][0]']   \n"," v2D)                                                                                             \n","                                                                                                  \n"," block12_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block12_sepconv1[0][0]']       \n"," alization)                                                                                       \n","                                                                                                  \n"," block12_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block12_sepconv1_bn[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," block12_sepconv2 (SeparableCon  (None, 2, 2, 728)   536536      ['block12_sepconv2_act[0][0]']   \n"," v2D)                                                                                             \n","                                                                                                  \n"," block12_sepconv2_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block12_sepconv2[0][0]']       \n"," alization)                                                                                       \n","                                                                                                  \n"," block12_sepconv3_act (Activati  (None, 2, 2, 728)   0           ['block12_sepconv2_bn[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," block12_sepconv3 (SeparableCon  (None, 2, 2, 728)   536536      ['block12_sepconv3_act[0][0]']   \n"," v2D)                                                                                             \n","                                                                                                  \n"," block12_sepconv3_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block12_sepconv3[0][0]']       \n"," alization)                                                                                       \n","                                                                                                  \n"," add_10 (Add)                   (None, 2, 2, 728)    0           ['block12_sepconv3_bn[0][0]',    \n","                                                                  'add_9[0][0]']                  \n","                                                                                                  \n"," block13_sepconv1_act (Activati  (None, 2, 2, 728)   0           ['add_10[0][0]']                 \n"," on)                                                                                              \n","                                                                                                  \n"," block13_sepconv1 (SeparableCon  (None, 2, 2, 728)   536536      ['block13_sepconv1_act[0][0]']   \n"," v2D)                                                                                             \n","                                                                                                  \n"," block13_sepconv1_bn (BatchNorm  (None, 2, 2, 728)   2912        ['block13_sepconv1[0][0]']       \n"," alization)                                                                                       \n","                                                                                                  \n"," block13_sepconv2_act (Activati  (None, 2, 2, 728)   0           ['block13_sepconv1_bn[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," block13_sepconv2 (SeparableCon  (None, 2, 2, 1024)  752024      ['block13_sepconv2_act[0][0]']   \n"," v2D)                                                                                             \n","                                                                                                  \n"," block13_sepconv2_bn (BatchNorm  (None, 2, 2, 1024)  4096        ['block13_sepconv2[0][0]']       \n"," alization)                                                                                       \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 1, 1, 1024)   745472      ['add_10[0][0]']                 \n","                                                                                                  \n"," block13_pool (MaxPooling2D)    (None, 1, 1, 1024)   0           ['block13_sepconv2_bn[0][0]']    \n","                                                                                                  \n"," batch_normalization_3 (BatchNo  (None, 1, 1, 1024)  4096        ['conv2d_3[0][0]']               \n"," rmalization)                                                                                     \n","                                                                                                  \n"," add_11 (Add)                   (None, 1, 1, 1024)   0           ['block13_pool[0][0]',           \n","                                                                  'batch_normalization_3[0][0]']  \n","                                                                                                  \n"," block14_sepconv1 (SeparableCon  (None, 1, 1, 1536)  1582080     ['add_11[0][0]']                 \n"," v2D)                                                                                             \n","                                                                                                  \n"," block14_sepconv1_bn (BatchNorm  (None, 1, 1, 1536)  6144        ['block14_sepconv1[0][0]']       \n"," alization)                                                                                       \n","                                                                                                  \n"," block14_sepconv1_act (Activati  (None, 1, 1, 1536)  0           ['block14_sepconv1_bn[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," block14_sepconv2 (SeparableCon  (None, 1, 1, 2048)  3159552     ['block14_sepconv1_act[0][0]']   \n"," v2D)                                                                                             \n","                                                                                                  \n"," block14_sepconv2_bn (BatchNorm  (None, 1, 1, 2048)  8192        ['block14_sepconv2[0][0]']       \n"," alization)                                                                                       \n","                                                                                                  \n"," block14_sepconv2_act (Activati  (None, 1, 1, 2048)  0           ['block14_sepconv2_bn[0][0]']    \n"," on)                                                                                              \n","                                                                                                  \n"," global_average_pooling2d (Glob  (None, 2048)        0           ['block14_sepconv2_act[0][0]']   \n"," alAveragePooling2D)                                                                              \n","                                                                                                  \n"," dropout (Dropout)              (None, 2048)         0           ['global_average_pooling2d[0][0]'\n","                                                                 ]                                \n","                                                                                                  \n"," fc1 (Dense)                    (None, 50)           102450      ['dropout[0][0]']                \n","                                                                                                  \n"," output (Dense)                 (None, 10)           510         ['fc1[0][0]']                    \n","                                                                                                  \n","==================================================================================================\n","Total params: 20,964,440\n","Trainable params: 20,909,912\n","Non-trainable params: 54,528\n","__________________________________________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","665/665 [==============================] - 91s 114ms/step - loss: 0.7521 - accuracy: 0.7519 - val_loss: 0.5937 - val_accuracy: 0.8183 - lr: 0.0010\n","Epoch 2/40\n","665/665 [==============================] - 73s 109ms/step - loss: 0.4001 - accuracy: 0.8694 - val_loss: 0.4790 - val_accuracy: 0.8519 - lr: 0.0010\n","Epoch 3/40\n","665/665 [==============================] - 73s 109ms/step - loss: 0.3055 - accuracy: 0.8991 - val_loss: 0.3872 - val_accuracy: 0.8780 - lr: 0.0010\n","Epoch 4/40\n","665/665 [==============================] - 73s 109ms/step - loss: 0.2492 - accuracy: 0.9194 - val_loss: 0.4726 - val_accuracy: 0.8528 - lr: 0.0010\n","Epoch 5/40\n","665/665 [==============================] - 73s 109ms/step - loss: 0.2286 - accuracy: 0.9268 - val_loss: 0.4314 - val_accuracy: 0.8720 - lr: 0.0010\n","Epoch 6/40\n","665/665 [==============================] - 73s 109ms/step - loss: 0.1811 - accuracy: 0.9411 - val_loss: 0.3839 - val_accuracy: 0.8801 - lr: 0.0010\n","Epoch 7/40\n","665/665 [==============================] - 73s 109ms/step - loss: 0.1711 - accuracy: 0.9436 - val_loss: 0.3750 - val_accuracy: 0.8917 - lr: 0.0010\n","Epoch 8/40\n","665/665 [==============================] - 73s 110ms/step - loss: 0.1309 - accuracy: 0.9569 - val_loss: 0.4496 - val_accuracy: 0.8723 - lr: 0.0010\n","Epoch 9/40\n","665/665 [==============================] - 73s 109ms/step - loss: 0.1379 - accuracy: 0.9565 - val_loss: 0.3104 - val_accuracy: 0.9103 - lr: 0.0010\n","Epoch 10/40\n","665/665 [==============================] - 73s 109ms/step - loss: 0.1165 - accuracy: 0.9620 - val_loss: 0.4232 - val_accuracy: 0.8711 - lr: 0.0010\n","Epoch 11/40\n","665/665 [==============================] - 73s 109ms/step - loss: 0.1042 - accuracy: 0.9675 - val_loss: 0.2964 - val_accuracy: 0.9136 - lr: 0.0010\n","Epoch 12/40\n","665/665 [==============================] - 73s 109ms/step - loss: 0.0931 - accuracy: 0.9699 - val_loss: 0.3266 - val_accuracy: 0.9075 - lr: 0.0010\n","Epoch 13/40\n","665/665 [==============================] - 73s 109ms/step - loss: 0.1143 - accuracy: 0.9631 - val_loss: 0.2984 - val_accuracy: 0.9139 - lr: 0.0010\n","Epoch 14/40\n","665/665 [==============================] - 73s 109ms/step - loss: 0.0742 - accuracy: 0.9771 - val_loss: 0.3558 - val_accuracy: 0.9081 - lr: 0.0010\n","Epoch 15/40\n","665/665 [==============================] - 73s 109ms/step - loss: 0.0762 - accuracy: 0.9755 - val_loss: 0.3468 - val_accuracy: 0.9084 - lr: 0.0010\n","Epoch 16/40\n","665/665 [==============================] - ETA: 0s - loss: 0.0723 - accuracy: 0.9770\n","Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n","665/665 [==============================] - 73s 109ms/step - loss: 0.0723 - accuracy: 0.9770 - val_loss: 0.8989 - val_accuracy: 0.7795 - lr: 0.0010\n","Epoch 17/40\n","665/665 [==============================] - 73s 109ms/step - loss: 0.0623 - accuracy: 0.9796 - val_loss: 0.2440 - val_accuracy: 0.9328 - lr: 2.0000e-04\n","Epoch 18/40\n","665/665 [==============================] - 73s 109ms/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 0.2789 - val_accuracy: 0.9351 - lr: 2.0000e-04\n","Epoch 19/40\n","665/665 [==============================] - 73s 109ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.2691 - val_accuracy: 0.9381 - lr: 2.0000e-04\n","Epoch 20/40\n","665/665 [==============================] - 73s 109ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.2887 - val_accuracy: 0.9391 - lr: 2.0000e-04\n","Epoch 21/40\n","665/665 [==============================] - 72s 109ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 0.3032 - val_accuracy: 0.9380 - lr: 2.0000e-04\n","Epoch 22/40\n","665/665 [==============================] - ETA: 0s - loss: 0.0062 - accuracy: 0.9981\n","Epoch 22: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n","665/665 [==============================] - 73s 109ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.3173 - val_accuracy: 0.9380 - lr: 2.0000e-04\n","Epoch 23/40\n","665/665 [==============================] - 73s 109ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.3024 - val_accuracy: 0.9397 - lr: 4.0000e-05\n","Epoch 24/40\n","665/665 [==============================] - 72s 109ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.3083 - val_accuracy: 0.9401 - lr: 4.0000e-05\n","Epoch 25/40\n","665/665 [==============================] - 73s 109ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.3112 - val_accuracy: 0.9403 - lr: 4.0000e-05\n","Epoch 26/40\n","665/665 [==============================] - 73s 109ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.3118 - val_accuracy: 0.9431 - lr: 4.0000e-05\n","Epoch 27/40\n","665/665 [==============================] - ETA: 0s - loss: 0.0016 - accuracy: 0.9996\n","Epoch 27: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n","665/665 [==============================] - 73s 109ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.3115 - val_accuracy: 0.9417 - lr: 4.0000e-05\n","Epoch 27: early stopping\n","157/157 [==============================] - 5s 29ms/step - loss: 0.3844 - accuracy: 0.9319\n","테스트 데이터 세트 evaluation 결과: [0.38444578647613525, 0.9319000244140625]\n"]}],"source":["# 만약 image_size를 64로 하려면 반드시 RAM이 여유분이 충분히 있는지 확인\n","history, evaluation_result = do_cifar10_train_evaluation(image_size=64, model_name='xception')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"wniirkqfYZH_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645188585068,"user_tz":-540,"elapsed":7,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"}},"outputId":"c25a0f9f-07dc-4179-8772-a4e3280dd405"},"outputs":[{"output_type":"stream","name":"stdout","text":["테스트 데이터세트 검증 결과: [0.38444578647613525, 0.9319000244140625]\n"]}],"source":["print('테스트 데이터세트 검증 결과:', evaluation_result)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ZfwoJpMUYZH_","colab":{"base_uri":"https://localhost:8080/","height":265},"executionInfo":{"status":"ok","timestamp":1645188586604,"user_tz":-540,"elapsed":431,"user":{"displayName":"Jaejin","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13986388466906754998"}},"outputId":"68ae8108-efac-422e-ee29-0561870723b6"},"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 576x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}],"source":["import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","def show_history(history):\n","    plt.figure(figsize=(8, 4))\n","    plt.yticks(np.arange(0, 1, 0.05))\n","    plt.xticks(np.arange(0, 30, 2))\n","    plt.plot(history.history['accuracy'], label='train')\n","    plt.plot(history.history['val_accuracy'], label='valid')\n","    plt.legend()\n","    \n","show_history(history)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Hz2z4A_YZH_"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"08_CIFAR10_Pretrained.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":0}