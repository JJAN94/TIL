# 심층 신경망(Deep Neural Network)

다수의 은닉층을 추가했기 떄문에 비선형 분류가 가능

비선형을 학습할 수 있다는 장점이 있지만, 학습을 위한 연산량이 많아지고 기울기 소멸 문제 등이 발생할 수 있다.

이를 방지하고자 드롭아웃, 렐루 함수, 배치 정규화 등을 적용해야한다.



# 합성곱 신경망(Convolutional Neural Network)

CNN은 합성곱층과 풀링층을 포함하는 이미지 처리 성능이 좋은 인공 신경망 알고리즘

- 각 층의 입출력 형상을 유지한다.
- 이미지의 공간 정보를 유지하면서 인접 이미지와 차이가 있는 특징을 효과적으로 인식한다.
- 복수 필터로 이미지의 특징을 추출하고 학습한다.
- 추출한 이미지의 특징을 모으고 강화하는 풀링층이 있다.
- 필터를 공유 파라미터로 사용하기 때문에 일반 인공 신경망과 비교하여 학습 파라미터가 매우 적다.



# 순환 신경망(Recurrent Neural Network)

RNN은 시계열 데이터(음악, 영상 등) 같은 시간 흐름에 따라 변화하는 데이터를 학습하기 위한 인공 신경망

여기서 순환(recurrent)란 뜻은 자기 자신을 참조한다는 것으로, 현재 결과가 이전 결과와 연관이 있다는 의미다.

- 시간성(temporal property)을 가진 데이터가 많다.
- 시간성 정보를 이용하여 데이터의 특징을 잘 다룬다.
- 시간에 따라 내용이 변하므로 데이터는 동적이고, 길이가 가변적이다.
- 매우 긴 데이터를 처리하는 연구가 활발히 진행되고 있다.

데이터가 길고(차원이 많고) 기울기 소멸 문제(gradient vanishing)가 있어 학습이 제대로 되지 않는 문제가 있다. 이를 해결하고자 메모리개념을 도입한 LSTM(Long-Short Term Memory) 알고리즘이 순환 신경망에서 많이 사용된다.

자연어 처리 분야에 많이 쓰인다.

언어 모델링, 텍스트 생성, 기계 번역, 음성 인식, 이미지 캡셔닝 등에 쓰인다.



# 제한된 볼츠만 머신(Restricted Boltzmann machine)

가시층(visible layer)과 은닉층(hidden layer)으로 구성된 모델이다. 심층 신뢰 신경망(DBN)을 구성하는 요소로 쓰인다.

가시층과 은닉층과만 연결된다.(은닉-은닉, 가시-가시 연결은 X)

- 차원 감소, 분류, 선형 회귀 분석, 협업필터링, 특성 값 학습(feature learning), 주제 모델링(topic modeling)에 사용
- 기울기 소멸 문제를 해결하기 위한 사전 학습 용도로 활용 가능
- 심층 신뢰 신경망의 요소로 사용됨



# 심층 신뢰 신경망(Deep Belief Network, DBN)

제한된 볼츠만 머신을 블록처럼 여러 층으로 쌓은 형태로 연결된 신경망.

사전 훈련된 제한된 볼츠만 머신을 층층이 쌓아 올린 구조며 레이블이 없는 데이터에 대한 비지도 학습이 가능하다.

- 순차적으로 심층 신뢰 신경망을 학습시켜 가면서 계층적 구조를 생성
- 비지도 학습 가능
- 위로 쌓아 올라갈수록 추상적 특성을 추출함
- 학습된 가중치를 다층 퍼셉트론의 가중치 초기값으로 사용



