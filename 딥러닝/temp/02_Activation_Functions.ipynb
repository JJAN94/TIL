{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f77aabab-14b0-4cb4-9730-ee161c96cc7b",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4abae4d-4056-497d-987d-5f69adc63e93",
   "metadata": {},
   "source": [
    "### Activation Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58905eab-2f43-45cf-b10d-4c3059166cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : (1, 5) / [[ 0.24473165  0.40281045 -0.35701185 -0.6260547   1.9396616 ]]\n",
      "Sigmoid(tensorflow) : (1, 5) \n",
      " [[0.56087935 0.59936273 0.4116831  0.34840566 0.87431496]]\n",
      "Sigmoid(manual) : (1, 5) \n",
      " [[0.56087935 0.59936273 0.4116831  0.34840566 0.87431496]]\n",
      "Tanh(tensorflow) : (1, 5) \n",
      " [[ 0.23995996  0.38235113 -0.34257928 -0.5553296   0.95950717]]\n",
      "Tanh(manual) : (1, 5) \n",
      " [[ 0.23995999  0.38235113 -0.34257928 -0.5553296   0.95950717]]\n",
      "ReLU(tensorflow) : (1, 5) \n",
      " [[0.24473165 0.40281045 0.         0.         1.9396616 ]]\n",
      "ReLU(manual) : (1, 5) \n",
      " [[0.24473165 0.40281045 0.         0.         1.9396616 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.math import exp, maximum\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "x = tf.random.normal(shape=(1,5)) # input setting\n",
    "\n",
    "sigmoid = Activation('sigmoid')\n",
    "tanh = Activation('tanh')\n",
    "relu = Activation('relu')\n",
    "\n",
    "# forward propagtion (using tensorflow)\n",
    "y_sigmoid_tf = sigmoid(x)\n",
    "y_tanh_tf = tanh(x)\n",
    "y_relu_tf = relu(x)\n",
    "\n",
    "# forward propagation (using manual)\n",
    "y_sigmoid_man = 1/(1 + exp(-x))\n",
    "y_tanh_man = (exp(x) - exp(-x))/(exp(x) + exp(-x))\n",
    "y_relu_man = maximum(x, 0)\n",
    "\n",
    "print(f'x : {x.shape} / {x.numpy()}')\n",
    "print(f'Sigmoid(tensorflow) : {y_sigmoid_tf.shape} \\n {y_sigmoid_tf.numpy()}')\n",
    "print(f'Sigmoid(manual) : {y_sigmoid_man.shape} \\n {y_sigmoid_man.numpy()}')\n",
    "print(f'Tanh(tensorflow) : {y_tanh_tf.shape} \\n {y_tanh_tf.numpy()}')\n",
    "print(f'Tanh(manual) : {y_tanh_man.shape} \\n {y_tanh_man.numpy()}')\n",
    "print(f'ReLU(tensorflow) : {y_relu_tf.shape} \\n {y_relu_tf.numpy()}')\n",
    "print(f'ReLU(manual) : {y_relu_man.shape} \\n {y_relu_man.numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3acdf5-2946-4454-b62e-0ca7918fea3a",
   "metadata": {},
   "source": [
    "### Activation in Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb525d17-521f-40be-a40a-2a622a2c4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23db67ee-ee68-44e7-8aeb-f152271334a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AN with Sigmoid : (1, 1)\n",
      "[[0.31202427]]\n",
      "AN with tanh : (1, 1)\n",
      "[[0.8543648]]\n",
      "AN with relu : (1, 1)\n",
      "[[0.2093778]]\n",
      "\n",
      "====================\n",
      "\n",
      "Activation Value(tensorflow) : (1, 1)\n",
      "[[0.31202427]]\n",
      "Activation Value(manual) : (1, 1)\n",
      "[[0.31202427]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.normal(shape=(1,5)) # input setting\n",
    "\n",
    "# artificial neurons\n",
    "dense_sigmoid = Dense(units=1 , activation='sigmoid')\n",
    "dense_tanh = Dense(units=1, activation='tanh')\n",
    "dense_relu = Dense(units=1, activation='relu')\n",
    "\n",
    "# forward propagation(tensorflow)\n",
    "y_sigmoid = dense_sigmoid(x)\n",
    "y_tanh = dense_tanh(x)\n",
    "y_relu = dense_relu(x)\n",
    "\n",
    "print(f'AN with Sigmoid : {y_sigmoid.shape}\\n{y_sigmoid.numpy()}')\n",
    "print(f'AN with tanh : {y_tanh.shape}\\n{y_tanh.numpy()}')\n",
    "print(f'AN with relu : {y_relu.shape}\\n{y_relu.numpy()}')\n",
    "\n",
    "# forward propagation(manual)\n",
    "print('\\n====================\\n')\n",
    "\n",
    "W, B = dense_sigmoid.get_weights()\n",
    "z = tf.linalg.matmul(x,W) + B\n",
    "a = 1 / (1+ exp(-z))\n",
    "print(f'Activation Value(tensorflow) : {y_sigmoid.shape}\\n{y_sigmoid.numpy()}')\n",
    "print(f'Activation Value(manual) : {a.shape}\\n{a.numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018c4ea9-ccef-4e48-ad34-1196855d54ab",
   "metadata": {},
   "source": [
    "## Artificial Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b14a81-f098-48ba-8834-4e5159bfd273",
   "metadata": {},
   "source": [
    "### Artificial Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0481fe8f-96cb-4b7b-83a9-8609fd2f5b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation :  relu\n",
      "y_tf : (1, 1)\n",
      "[[0.]]\n",
      "y_man : (1, 1)\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.math import exp, maximum\n",
    "\n",
    "# activation = 'sigmoid'\n",
    "# activation = 'tanh'\n",
    "activation = 'relu'\n",
    "\n",
    "x = tf.random.uniform(shape=(1,10))\n",
    "\n",
    "dense = Dense(units=1, activation=activation)\n",
    "\n",
    "y_tf = dense(x)\n",
    "W, B = dense.get_weights()\n",
    "\n",
    "# calculate activation value manually\n",
    "y_man = tf.linalg.matmul(x, W) + B\n",
    "if activation == 'sigmoid':\n",
    "    y_man = 1 / (1 + exp(-y_man))\n",
    "elif activation == 'tanh':\n",
    "    y_man = (exp(y_man) - exp(-y_man)) / (exp(y_man) + exp(-y_man))\n",
    "elif activation == 'relu':\n",
    "    y_man = maximum(y_man ,0)\n",
    "    \n",
    "print('Activation : ', activation)\n",
    "print(f'y_tf : {y_tf.shape}\\n{y_tf.numpy()}')\n",
    "print(f'y_man : {y_man.shape}\\n{y_man.numpy()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5498369-f2d9-4f3a-9cbf-115979f3d401",
   "metadata": {},
   "source": [
    "## Minibatches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb02e1-8eb6-470e-98aa-e7afb1389e41",
   "metadata": {},
   "source": [
    "### Shapes of Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "555954bf-e17a-4c97-aca4-00a0048a0a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 10)\n",
      "Shape of x : (8, 10)\n",
      "Shape of W : (10, 1)\n",
      "Shape of B : (1,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "N, n_feature = 8, 10 # N이 미니배치의 사이즈인데 이것은 가중치와 편향(bias)에 영향을 미치지 않는다.\n",
    "x = tf.random.normal(shape=(N, n_feature)) # generate minibatch\n",
    "print(x.shape)\n",
    "\n",
    "dense = Dense(units=1, activation='relu') # an AN\n",
    "y = dense(x) # forward propagation\n",
    "\n",
    "W, B = dense.get_weights() # get weights/bias\n",
    "\n",
    "# print results\n",
    "print(f\"Shape of x : {x.shape}\")\n",
    "print(f'Shape of W : {W.shape}')\n",
    "print(f'Shape of B : {B.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a5cf0f-04cc-42ea-8994-b870192b7bfe",
   "metadata": {},
   "source": [
    "### Output Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58361c45-6bd1-4fba-b453-ad0ca6272b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output(tensorflow) : [[0.32297447]\n",
      " [0.18615751]\n",
      " [0.3721323 ]\n",
      " [0.4763674 ]\n",
      " [0.50935024]\n",
      " [0.5069301 ]\n",
      " [0.520999  ]\n",
      " [0.5456856 ]]\n",
      "Output(manual) : [[0.32297447]\n",
      " [0.18615751]\n",
      " [0.3721323 ]\n",
      " [0.4763674 ]\n",
      " [0.50935024]\n",
      " [0.5069301 ]\n",
      " [0.520999  ]\n",
      " [0.5456856 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "N, n_feature = 8, 10 # set input params\n",
    "x = tf.random.normal(shape=(N, n_feature)) # generate minibatch\n",
    "\n",
    "dense = Dense(units=1, activation='sigmoid') # an AN\n",
    "y_tf = dense(x) # forward propagation(tensorflow)\n",
    "\n",
    "W, B = dense.get_weights() # get weights/bias\n",
    "\n",
    "y_man = tf.linalg.matmul(x, W) + B # forward propagation (manual)\n",
    "y_man = 1 / (1 + exp(-y_man))\n",
    "# print results\n",
    "print(f'Output(tensorflow) : {y_tf.numpy()}')\n",
    "print(f'Output(manual) : {y_man.numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c059c63-bf16-4047-b29c-a49a8449c435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensor",
   "language": "python",
   "name": "tensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
